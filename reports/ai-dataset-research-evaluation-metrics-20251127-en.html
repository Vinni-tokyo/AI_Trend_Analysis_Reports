<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Global AI Dataset Research & Evaluation Metrics Trend Report 2025</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --primary-navy: #001e5c;
            --secondary-navy: #003d8f;
            --accent-navy: #0052b8;
            --primary-color: #1a1a1a;
            --secondary-color: #4a4a4a;
            --tertiary-color: #808080;
            --bg-white: #ffffff;
            --bg-subtle: #fafafa;
            --border-color: #e5e5e5;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.7;
            color: #1a1a1a;
            background: #fafafa;
            padding: 0;
            font-size: 16px;
            font-weight: 400;
        }
        .container {
            max-width: 1000px;
            margin: 2rem auto;
            background: white;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }
        .header {
            background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-navy) 100%);
            color: white;
            padding: 2rem 2.5rem 1.5rem;
            text-align: center;
            position: relative;
            border-bottom: 3px solid var(--primary-navy);
        }
        .header-actions {
            position: absolute;
            top: 1rem;
            right: 1.5rem;
            display: flex;
            gap: 0.75rem;
            z-index: 10;
        }
        .back-btn {
            padding: 0.3rem 0.6rem;
            border: 1px solid rgba(255,255,255,0.3);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.2s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }
        .back-btn:hover {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.5);
        }
        .language-switcher {
            display: flex;
            gap: 0.3rem;
        }
        .lang-btn {
            padding: 0.3rem 0.6rem;
            border: 1px solid rgba(255,255,255,0.3);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        .lang-btn:hover {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.5);
        }
        .lang-btn.active {
            background: white;
            color: var(--primary-navy);
            border-color: white;
        }
        .header h1 {
            font-size: 1.2rem;
            margin-bottom: 0.15rem;
            line-height: 1.3;
        }
        .header .subtitle {
            font-size: 0.9rem;
            margin-top: 0.25rem;
            opacity: 0.9;
        }
        .header .meta {
            margin-top: 0.5rem;
            font-size: 0.75rem;
            opacity: 0.8;
        }
        .content { padding: 1.5rem 2rem; }
        .section { margin-bottom: 2rem; page-break-inside: avoid; }
        .section-title {
            font-size: 1.4rem;
            color: #1a1a1a;
            margin-bottom: 0.5rem;
            padding-bottom: 0.25rem;
            border-bottom: 2px solid #1a1a1a;
        }
        .subsection-title {
            font-size: 1.1rem;
            color: #1a1a1a;
            margin-top: 1.2rem;
            margin-bottom: 0.5rem;
            font-weight: 600;
        }
        .executive-summary {
            background: #fafafa;
            border-left: 3px solid #e5e5e5;
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 4px;
        }
        .key-findings { list-style: none; }
        .key-findings li {
            padding: 0.4rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.95rem;
        }
        .key-findings li:before {
            content: "‚Üí";
            position: absolute;
            left: 0;
            color: #1a1a1a;
            font-weight: bold;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.85rem;
        }
        th, td { padding: 0.6rem; text-align: left; border-bottom: 1px solid #e5e5e5; }
        th { background: #fafafa; font-weight: 600; }
        tr:hover { background: #fafafa; }
        .chart-container {
            position: relative;
            height: 280px;
            margin: 1rem 0;
            padding: 0.75rem;
            border-radius: 4px;
            border: 1px solid #e5e5e5;
        }
        .sources {
            background: #fafafa;
            padding: 1rem;
            border-radius: 4px;
            margin-top: 1rem;
            font-size: 0.8rem;
        }
        .sources ul { list-style: none; }
        .sources li { padding: 0.25rem 0; }
        .sources a { color: #0052b8; text-decoration: none; }
        .sources a:hover { text-decoration: underline; }
        .trend-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin-bottom: 1rem; }
        .trend-card {
            background: white;
            border: 1px solid #e5e5e5;
            border-radius: 4px;
            padding: 1.2rem;
        }
        .trend-card h4 { font-size: 1rem; margin-bottom: 0.5rem; color: #1a1a1a; }
        .trend-card p { font-size: 0.9rem; line-height: 1.6; }
        .related-links {
            background: #f0f7ff;
            border-left: 3px solid #0052b8;
            padding: 0.75rem 1rem;
            margin: 1rem 0;
            border-radius: 4px;
            font-size: 0.9rem;
        }
        .related-links strong {
            color: #001e5c;
            font-size: 0.85rem;
            display: block;
            margin-bottom: 0.4rem;
        }
        .related-links a {
            color: #0052b8;
            text-decoration: none;
            font-weight: 500;
        }
        .related-links a:hover {
            text-decoration: underline;
        }
        .stat-highlight {
            background: linear-gradient(135deg, #f0f7ff 0%, #e8f4ff 100%);
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1rem 0;
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 1rem;
            text-align: center;
        }
        .stat-item .stat-value {
            font-size: 1.5rem;
            font-weight: 700;
            color: var(--primary-navy);
        }
        .stat-item .stat-label {
            font-size: 0.8rem;
            color: #4a4a4a;
            margin-top: 0.25rem;
        }
        @media (max-width: 600px) {
            .trend-grid { grid-template-columns: 1fr; }
            .stat-highlight { grid-template-columns: repeat(2, 1fr); }
            .header-actions { flex-direction: column; gap: 0.3rem; }
        }
        @media print {
            body { padding: 0; font-size: 12px; }
            .container { box-shadow: none; }
            .header-actions { display: none; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="header-actions">
                <a href="../index.html" class="back-btn">‚Üê Home</a>
                <div class="language-switcher">
                    <button onclick="window.location.href='ai-dataset-research-evaluation-metrics-20251127-ja.html'" class="lang-btn">Êó•Êú¨Ë™û</button>
                    <button onclick="window.location.href='ai-dataset-research-evaluation-metrics-20251127-ko.html'" class="lang-btn">ÌïúÍµ≠Ïñ¥</button>
                    <button onclick="window.location.href='ai-dataset-research-evaluation-metrics-20251127-en.html'" class="lang-btn active">English</button>
                </div>
            </div>
            <h1>Global AI Dataset Research &<br>Evaluation Metrics Trend Report</h1>
            <div class="subtitle">From MNIST, ImageNet, MovieLens to Latest LLM Datasets: In-Depth Analysis of Quality Assessment & Fairness Metrics</div>
            <div class="meta">Report Date: November 27, 2025 | Standard Report (5-8 pages)</div>
        </div>

        <div class="content">
            <!-- Key Statistics -->
            <div class="stat-highlight">
                <div class="stat-item">
                    <div class="stat-value">30T+</div>
                    <div class="stat-label">RedPajama-V2 Tokens</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">5.85B</div>
                    <div class="stat-label">LAION-5B Image-Text Pairs</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">35.2%</div>
                    <div class="stat-label">Synthetic Data Market CAGR</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">200+</div>
                    <div class="stat-label">BIG-Bench Tasks</div>
                </div>
            </div>

            <!-- SECTION 1: Trend Analysis -->
            <section id="trends" class="section">
                <h2 class="section-title">Top 5 Key Trends</h2>

                <h3 class="subsection-title">1. Evolution and Limitations of Classic Benchmark Datasets</h3>
                <p><strong>Current State:</strong> MNIST was developed in 1999 by Yann LeCun et al. as a handwritten digit dataset, known as the "Hello World" of machine learning. However, with 2024's state-of-the-art supercomputers and algorithms, MNIST is considered "solved," with most models easily achieving 95%+ accuracy. CIFAR-10/100 served as a "bridge" between MNIST and ImageNet, but it too is showing limitations.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Classic Datasets</h4>
                        <p>‚Ä¢ <strong>MNIST:</strong> 60,000 training images, 10,000 test images, 10 categories<br>
                        ‚Ä¢ <strong>CIFAR-10:</strong> 60,000 32√ó32 pixel images, 10 categories<br>
                        ‚Ä¢ <strong>ImageNet:</strong> 14+ million images, 20,000+ categories</p>
                    </div>
                    <div class="trend-card">
                        <h4>Alternative/Extended Datasets</h4>
                        <p>‚Ä¢ <strong>Fashion-MNIST:</strong> Direct MNIST replacement, 10 fashion categories<br>
                        ‚Ä¢ <strong>EMNIST/KMNIST:</strong> Extended/Kuzushiji MNIST<br>
                        ‚Ä¢ <strong>ObjectNet:</strong> Test-only, no training data</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>üîó Related Links:</strong>
                    <a href="https://yann.lecun.com/exdb/mnist/" target="_blank">MNIST</a> |
                    <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">CIFAR</a> |
                    <a href="https://www.image-net.org/" target="_blank">ImageNet</a> |
                    <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">Fashion-MNIST</a>
                </div>

                <p><strong>Outlook:</strong> Continual Learning research demands benchmarks that include heterogeneous tasks beyond single concept sets like MNIST/SVHN/ImageNet/CIFAR10. Model development is accelerating to handle transitions from grayscale to RGB, varying image sizes, and concept count changes.</p>

                <h3 class="subsection-title">2. Scaling and Curation of LLM Training Datasets</h3>
                <p><strong>Current State:</strong> RedPajama-V2 is the largest open LLM training dataset with 30 trillion tokens. It collected over 100 billion text documents from 84 CommonCrawl snapshots and pre-computed 40+ quality annotations. It supports 5 languages: English, French, Spanish, German, and Italian.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>RedPajama-V1 Composition (1.2T Tokens)</h4>
                        <p>‚Ä¢ <strong>CommonCrawl:</strong> 878 billion tokens<br>
                        ‚Ä¢ <strong>C4:</strong> 175 billion tokens<br>
                        ‚Ä¢ <strong>GitHub:</strong> 59 billion tokens<br>
                        ‚Ä¢ <strong>Books/ArXiv/Wiki:</strong> 78 billion tokens</p>
                    </div>
                    <div class="trend-card">
                        <h4>2025 Trends</h4>
                        <p>‚Ä¢ <strong>Advanced Deduplication:</strong> DeepSeek removes 20-30% duplicate data<br>
                        ‚Ä¢ <strong>Quality over Quantity:</strong> Focus on diverse tokens<br>
                        ‚Ä¢ <strong>FineWeb-Edu:</strong> Education-focused 1.3T tokens</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>üîó Related Links:</strong>
                    <a href="https://www.together.ai/blog/redpajama-data-v2" target="_blank">RedPajama-V2</a> |
                    <a href="https://commoncrawl.org/" target="_blank">CommonCrawl</a> |
                    <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" target="_blank">FineWeb-Edu</a>
                </div>

                <p><strong>Outlook:</strong> Common Corpus is gaining attention as the largest collection for ethical LLM pre-training. Multimodal datasets like FineVideo (43,000 videos) and Mosel (1 million audio hours) are being derived from YouTube Commons.</p>

                <h3 class="subsection-title">3. Multimodal & Recommendation System Datasets</h3>
                <p><strong>Current State:</strong> LAION-5B is a massive multimodal dataset containing 5.85 billion image-text pairs, used for training text-to-image generation models like Stable Diffusion and DALL¬∑E. For recommendation systems, MovieLens (founded 1997) is widely used as the gold standard for collaborative filtering.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Multimodal Datasets</h4>
                        <p>‚Ä¢ <strong>LAION-5B:</strong> 5.85 billion image-text pairs<br>
                        ‚Ä¢ <strong>COCO:</strong> 328K images, 2.5M labels<br>
                        ‚Ä¢ <strong>Google Open Images V6:</strong> Latest version, relationships & segmentation</p>
                    </div>
                    <div class="trend-card">
                        <h4>Recommendation System Datasets</h4>
                        <p>‚Ä¢ <strong>MovieLens:</strong> 100K-25M ratings, 32+ papers<br>
                        ‚Ä¢ <strong>Amazon Reviews:</strong> 24 papers, multi-category<br>
                        ‚Ä¢ <strong>Netflix Prize/Last.fm/Yelp:</strong> Representative benchmarks</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>üîó Related Links:</strong>
                    <a href="https://laion.ai/" target="_blank">LAION</a> |
                    <a href="https://cocodataset.org/" target="_blank">COCO</a> |
                    <a href="https://grouplens.org/datasets/movielens/" target="_blank">MovieLens</a>
                </div>

                <p><strong>Outlook:</strong> Key challenges for recommendation systems include data sparsity, scalability, and the need for diverse recommendations. Hybrid approaches to solve collaborative filtering's "cold start" problem (handling new items/users) became active in 2024 research.</p>

                <h3 class="subsection-title">4. Evolution of NLP Benchmarks: From GLUE to BIG-Bench</h3>
                <p><strong>Current State:</strong> GLUE (General Language Understanding Evaluation) is a collection of resources for training, evaluating, and analyzing natural language understanding systems. After GLUE was "solved" in 2019, the same team released the more challenging SuperGLUE. Notably, DeBERTa-v3 outperformed PaLM on SuperGLUE at 1/360th the size, demonstrating the importance of architecture and pre-training techniques.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Major NLP Benchmarks</h4>
                        <p>‚Ä¢ <strong>GLUE:</strong> Sentence-level tasks, NLU standard<br>
                        ‚Ä¢ <strong>SuperGLUE:</strong> Coreference resolution, QA, long-form reasoning<br>
                        ‚Ä¢ <strong>MMLU:</strong> Humanities, social sciences, STEM knowledge evaluation</p>
                    </div>
                    <div class="trend-card">
                        <h4>Next-Generation Benchmarks</h4>
                        <p>‚Ä¢ <strong>BIG-Bench:</strong> 200+ tasks, beyond traditional NLP<br>
                        ‚Ä¢ <strong>MMMLU:</strong> Expert-translated version in 14 languages<br>
                        ‚Ä¢ <strong>CMMLU:</strong> Chinese version, 1,528 questions across 67 subjects</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>üîó Related Links:</strong>
                    <a href="https://gluebenchmark.com/" target="_blank">GLUE</a> |
                    <a href="https://super.gluebenchmark.com/" target="_blank">SuperGLUE</a> |
                    <a href="https://github.com/google/BIG-bench" target="_blank">BIG-Bench</a> |
                    <a href="https://paperswithcode.com/dataset/mmlu" target="_blank">MMLU</a>
                </div>

                <p><strong>Outlook:</strong> As language models become more complex, ROUGE or BLEU scores alone cannot capture their capabilities. Future trends include domain-specific benchmarks (BLUE for healthcare, LexGLUE for legal), dynamic, multimodal, and privacy-preserving benchmarks.</p>

                <h3 class="subsection-title">5. Explosive Growth of Synthetic Data Generation</h3>
                <p><strong>Current State:</strong> In 2024, synthetic data holds 30%+ market share in AI/ML training, with market size valued at approximately $310 million. Growth is projected at 35.2% CAGR through 2034. By 2025, synthetic data generation has become an operational necessity rather than an experimental capability.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Generation Methods</h4>
                        <p>‚Ä¢ <strong>GAN:</strong> Generates realistic images, audio, behaviors<br>
                        ‚Ä¢ <strong>Diffusion Models:</strong> Beyond images to structured data<br>
                        ‚Ä¢ <strong>LLM:</strong> Text, dialogue, document generation</p>
                    </div>
                    <div class="trend-card">
                        <h4>Industry Applications</h4>
                        <p>‚Ä¢ <strong>Healthcare:</strong> Anonymized patient records for diagnostic AI<br>
                        ‚Ä¢ <strong>Autonomous Driving:</strong> Simulating rare critical events<br>
                        ‚Ä¢ <strong>Finance:</strong> Synthetic credit card transactions for fraud detection</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>üîó Related Links:</strong>
                    <a href="https://arxiv.org/abs/2403.04190" target="_blank">Synthetic Data Survey</a> |
                    <a href="https://syndata4cv.github.io/" target="_blank">CVPR 2025 Synthetic Data Workshop</a>
                </div>

                <p><strong>Outlook:</strong> LLM-based data augmentation is a major trend in 2024-2025. Challenges remain including "domain gap" between synthetic and real-world data, bias transfer, and quality maintenance. Healthcare and finance require careful validation of synthetic data for regulatory compliance.</p>
            </section>

            <!-- SECTION 2: In-Depth Evaluation Metrics Analysis -->
            <section id="metrics" class="section">
                <h2 class="section-title">In-Depth Analysis of Dataset Evaluation Metrics</h2>

                <h3 class="subsection-title">Fairness & Bias Metrics</h3>
                <p>Five key metrics have been established for fairness evaluation: Equalized Odds (EO), Equality of Opportunity, Demographic Parity (DP), Individual Differential Fairness, and MDFA.</p>

                <table>
                    <thead>
                        <tr>
                            <th>Metric Name</th>
                            <th>Definition</th>
                            <th>Application Scenarios</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Demographic Parity (DP)</strong></td>
                            <td>Ensures decisions are independent of sensitive attributes</td>
                            <td>Hiring, loan decisions</td>
                        </tr>
                        <tr>
                            <td><strong>Equalized Odds (EO)</strong></td>
                            <td>Ensures fairness across positive and negative predictions</td>
                            <td>Medical diagnosis, risk assessment</td>
                        </tr>
                        <tr>
                            <td><strong>Equality of Opportunity</strong></td>
                            <td>Equal treatment for individuals meeting same criteria</td>
                            <td>Education, promotion decisions</td>
                        </tr>
                        <tr>
                            <td><strong>Individual Differential Fairness</strong></td>
                            <td>Fair predictions among similar individuals</td>
                            <td>Personalized services</td>
                        </tr>
                        <tr>
                            <td><strong>MDFA</strong></td>
                            <td>Multi-dimensional fairness assessment</td>
                            <td>Complex attribute analysis</td>
                        </tr>
                    </tbody>
                </table>

                <h3 class="subsection-title">Data Quality & Valuation Metrics</h3>
                <p>As a Data-Centric AI approach, Data Shapley quantifies the importance of individual data tuples in data-driven learning algorithms, identifying quality and value through their contribution to overall model performance.</p>

                <table>
                    <thead>
                        <tr>
                            <th>Method</th>
                            <th>Characteristics</th>
                            <th>Computational Complexity</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Data Shapley</strong></td>
                            <td>Game theory-based, individual data contribution evaluation</td>
                            <td>O(2^N) ‚Üí Improved O(N log N)</td>
                        </tr>
                        <tr>
                            <td><strong>CHG Shapley (ICLR 2025)</strong></td>
                            <td>Closed-form Shapley value, computed with single model retraining</td>
                            <td>Quadratic improvement</td>
                        </tr>
                        <tr>
                            <td><strong>Unlearning Shapley (2025)</strong></td>
                            <td>Leverages machine unlearning, no retraining required</td>
                            <td>Monte Carlo sampling</td>
                        </tr>
                        <tr>
                            <td><strong>Chunked Data Shapley</strong></td>
                            <td>Large-scale dataset quality evaluation, 6-dimension quality taxonomy</td>
                            <td>Scalable</td>
                        </tr>
                    </tbody>
                </table>

                <p style="margin-top: 1rem;"><strong>Six Dimensions of Data Quality (Mohammed et al., 2025a):</strong> Expressiveness, Completeness, Feature Accuracy, Target Accuracy, Uniqueness, Target Class Balance</p>

                <h3 class="subsection-title">LLM Bias Benchmarks</h3>
                <p>AI fairness researchers create benchmarks containing datasets and associated metrics to measure specific dimensions of AI fairness. BBQ (Bias Benchmark for QA) uses multiple-choice questions to measure language model bias across various demographic groups.</p>

                <table>
                    <thead>
                        <tr>
                            <th>Benchmark</th>
                            <th>Measurement Target</th>
                            <th>Categories</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>BBQ</strong></td>
                            <td>Demographic group bias</td>
                            <td>Ageism, racism, sexism, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>Sony FHIBE</strong></td>
                            <td>Demographic, physical attributes, environmental factors</td>
                            <td>81 countries/regions, 10,318 images</td>
                        </tr>
                        <tr>
                            <td><strong>Parity Benchmark</strong></td>
                            <td>LLM bias quantification</td>
                            <td>Colonialism, colorism, homophobia</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- SECTION 3: Toolkit Comparison -->
            <section id="competitive" class="section">
                <h2 class="section-title">Fairness & Quality Evaluation Toolkit Comparison</h2>

                <table>
                    <thead>
                        <tr>
                            <th>Tool Name</th>
                            <th>Developer</th>
                            <th>Characteristics</th>
                            <th>Key Features</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>AI Fairness 360</strong></td>
                            <td>IBM</td>
                            <td>Transferring fairness research to industry settings</td>
                            <td>70+ fairness metrics, bias mitigation algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>Aequitas</strong></td>
                            <td>University of Chicago</td>
                            <td>Subgroup-specific bias/fairness testing</td>
                            <td>Report generation, policymaker-oriented</td>
                        </tr>
                        <tr>
                            <td><strong>Vertex AI Fairness</strong></td>
                            <td>Google Cloud</td>
                            <td>Pre-training data bias detection</td>
                            <td>Data bias metrics, evaluation tools</td>
                        </tr>
                        <tr>
                            <td><strong>Papers With Code</strong></td>
                            <td>Meta AI</td>
                            <td>Dataset search & comparison platform</td>
                            <td>Benchmark leaderboards, dataset catalog</td>
                        </tr>
                    </tbody>
                </table>

                <h3 class="subsection-title">Tool Comparison Radar Chart</h3>
                <div class="chart-container">
                    <canvas id="toolsChart"></canvas>
                </div>

                <div class="related-links">
                    <strong>üîó Related Links:</strong>
                    <a href="https://aif360.mybluemix.net/" target="_blank">AI Fairness 360</a> |
                    <a href="http://aequitas.dssg.io/" target="_blank">Aequitas</a> |
                    <a href="https://cloud.google.com/vertex-ai/docs/evaluation/intro-evaluation-fairness" target="_blank">Vertex AI Fairness</a> |
                    <a href="https://paperswithcode.com/datasets" target="_blank">Papers With Code</a>
                </div>
            </section>

            <!-- SECTION 4: Application Ideas -->
            <section id="application-ideas" class="section">
                <h2 class="section-title">Application Ideas</h2>
                <p style="margin-bottom: 1rem; color: #4a4a4a;">Introducing key application approaches observed in the market.</p>

                <div style="background: #fafafa; padding: 1.5rem; border-left: 3px solid #e5e5e5;">
                    <p style="margin-bottom: 1rem; line-height: 1.6;">1. <strong>Data Quality Auditing with Data Shapley</strong> - Quantify training data contributions, automatically identify and remove low-quality data to improve model performance</p>
                    <p style="margin-bottom: 1rem; line-height: 1.6;">2. <strong>Bias Detection Pipeline with AI Fairness 360</strong> - Measure fairness metrics for hiring and loan models, apply mitigation algorithms</p>
                    <p style="line-height: 1.6;">3. <strong>Training Data Expansion via Synthetic Data Generation</strong> - Augment data for rare scenarios (medical diagnosis, fraud detection) while preserving privacy</p>
                </div>
            </section>

            <!-- SECTION 5: Executive Summary -->
            <section id="executive-summary" class="section">
                <h2 class="section-title">Executive Summary</h2>

                <div class="executive-summary">
                    <h3 style="font-size: 1rem; margin-bottom: 0.5rem; color: #1a1a1a;">Key Points</h3>
                    <ul class="key-findings">
                        <li><strong>Classic Benchmark Limitations:</strong> MNIST is "solved" status, heterogeneous task benchmarks needed for continual learning</li>
                        <li><strong>LLM Dataset Scaling:</strong> RedPajama-V2 (30 trillion tokens), shift toward quality annotations</li>
                        <li><strong>Synthetic Data Market Surge:</strong> 30%+ market share in 2024, projected 35.2% CAGR through 2034</li>
                        <li><strong>Fairness Evaluation Standardization:</strong> 5 key metrics established, toolkits like AI Fairness 360 widely adopted</li>
                        <li><strong>Data Shapley Practicalization:</strong> Computational efficiency improved (O(2^N)‚ÜíO(N log N)), enabling large-scale dataset evaluation</li>
                    </ul>

                    <h3 style="font-size: 1rem; margin-top: 1rem; margin-bottom: 0.5rem; color: #1a1a1a;">Recommendations by Use Case</h3>
                    <p style="font-size: 0.95rem; line-height: 1.8;">
                        <strong>Computer Vision Research ‚Üí</strong> Fashion-MNIST, COCO, ObjectNet (test-only)<br>
                        Reason: Overcomes MNIST limitations, closer to real-world benchmarks<br><br>
                        <strong>LLM Training ‚Üí</strong> RedPajama-V2, FineWeb-Edu (education-focused)<br>
                        Reason: Includes quality annotations, deduplication completed<br><br>
                        <strong>Fairness Evaluation ‚Üí</strong> AI Fairness 360 + Sony FHIBE<br>
                        Reason: Comprehensive metrics, global diversity
                    </p>
                </div>

                <p style="margin-top: 1rem; font-size: 1rem; color: #4a4a4a;"><strong>Overall Assessment:</strong> Positive (Data-Centric AI paradigm establishment and evaluation methodology maturation in progress)</p>
            </section>

            <!-- SECTION 6: Key Terminology -->
            <section id="terminology" class="section">
                <h2 class="section-title" style="font-size: 1rem; margin-bottom: 0.4rem;">Key Terminology</h2>
                <div style="background: #fafafa; padding: 0.75rem 1rem; border-left: 3px solid #e5e5e5; font-size: 0.9rem;">
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Data Shapley</strong> - A method applying game theory's Shapley value to quantify how much each training data point contributes to model performance
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Demographic Parity</strong> - A fairness criterion requiring AI decisions to be statistically independent of sensitive attributes like race or gender
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>CommonCrawl</strong> - An open web crawl archive, a major data source for LLM training. However, raw data contains noise and requires preprocessing
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Continual Learning</strong> - An ML research field focused on learning new knowledge while not forgetting past knowledge
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Synthetic Data</strong> - Data generated by algorithms (GANs, diffusion models, LLMs) rather than real-world collection. Effective for privacy protection and addressing data scarcity
                    </div>
                    <div>
                        <strong>GLUE/SuperGLUE</strong> - Benchmark suites for evaluating natural language understanding capabilities. SuperGLUE is the more challenging version released after GLUE was "solved"
                    </div>
                </div>
            </section>

            <!-- SECTION 7: Sources -->
            <section id="sources" class="section">
                <div class="sources">
                    <h3 style="font-size: 1rem; margin-bottom: 0.5rem;">References</h3>
                    <p><strong>Data Collection:</strong> November 27, 2025</p>
                    <ul>
                        <li>‚Ä¢ <a href="https://www.together.ai/blog/redpajama-data-v2" target="_blank">Together AI - RedPajama-Data-v2: 30 Trillion Tokens</a></li>
                        <li>‚Ä¢ <a href="https://arxiv.org/html/2411.12372v1" target="_blank">arXiv - RedPajama: An Open Dataset for Training LLMs</a></li>
                        <li>‚Ä¢ <a href="https://gluebenchmark.com/" target="_blank">GLUE Benchmark Official</a></li>
                        <li>‚Ä¢ <a href="https://arxiv.org/pdf/1908.09635" target="_blank">arXiv - A Survey on Bias and Fairness in Machine Learning</a></li>
                        <li>‚Ä¢ <a href="https://www.mdpi.com/2504-2289/7/1/15" target="_blank">MDPI - Bias and Unfairness in ML: Systematic Review</a></li>
                        <li>‚Ä¢ <a href="https://openreview.net/forum?id=uVMZgtw2pf" target="_blank">ICLR 2025 - CHG Shapley: Efficient Data Valuation</a></li>
                        <li>‚Ä¢ <a href="https://arxiv.org/html/2508.16255" target="_blank">CIKM 2025 - Chunked Data Shapley</a></li>
                        <li>‚Ä¢ <a href="https://www.shaped.ai/blog/movielens-dataset-the-essential-benchmark-for-recommender-systems" target="_blank">Shaped - MovieLens Dataset Benchmark</a></li>
                        <li>‚Ä¢ <a href="https://laion.ai/" target="_blank">LAION - Large-scale AI Open Network</a></li>
                        <li>‚Ä¢ <a href="https://ai.sony/articles/Groundbreaking-Fairness-Evaluation-Dataset-From-Sony%20AI%20/" target="_blank">Sony AI - FHIBE Fairness Dataset</a></li>
                        <li>‚Ä¢ <a href="https://arxiv.org/abs/2403.04190" target="_blank">arXiv - Generative AI for Synthetic Data Generation</a></li>
                        <li>‚Ä¢ <a href="https://paperswithcode.com/datasets" target="_blank">Papers With Code - ML Datasets</a></li>
                    </ul>
                </div>
            </section>
        </div>
    </div>

    <script>
        const ctx = document.getElementById('toolsChart').getContext('2d');
        new Chart(ctx, {
            type: 'radar',
            data: {
                labels: ['Fairness Metrics', 'Ease of Use', 'Scalability', 'Documentation', 'Community'],
                datasets: [
                    {
                        label: 'AI Fairness 360',
                        data: [95, 75, 80, 90, 85],
                        borderColor: 'rgb(59, 130, 246)',
                        backgroundColor: 'rgba(59, 130, 246, 0.2)'
                    },
                    {
                        label: 'Aequitas',
                        data: [70, 90, 65, 75, 60],
                        borderColor: 'rgb(34, 197, 94)',
                        backgroundColor: 'rgba(34, 197, 94, 0.2)'
                    },
                    {
                        label: 'Vertex AI Fairness',
                        data: [60, 85, 95, 85, 80],
                        borderColor: 'rgb(249, 115, 22)',
                        backgroundColor: 'rgba(249, 115, 22, 0.2)'
                    },
                    {
                        label: 'Papers With Code',
                        data: [40, 95, 90, 70, 95],
                        borderColor: 'rgb(168, 85, 247)',
                        backgroundColor: 'rgba(168, 85, 247, 0.2)'
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 100
                    }
                },
                plugins: {
                    legend: {
                        position: 'bottom'
                    }
                }
            }
        });
    </script>
</body>
</html>
