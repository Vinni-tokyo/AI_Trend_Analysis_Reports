<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Algorithms for Recommendation Systems: Top 5 Spotlight Technologies</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --primary-navy: #001e5c;
            --secondary-navy: #003d8f;
            --accent-navy: #0052b8;
            --primary-color: #1a1a1a;
            --secondary-color: #4a4a4a;
            --tertiary-color: #808080;
            --bg-white: #ffffff;
            --bg-subtle: #fafafa;
            --border-color: #e5e5e5;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.7;
            color: #1a1a1a;
            background: #fafafa;
            padding: 0;
            font-size: 16px;
            font-weight: 400;
        }
        .container {
            max-width: 1000px;
            margin: 2rem auto;
            background: white;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }
        .header {
            background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-navy) 100%);
            color: white;
            padding: 2rem 2.5rem 1.5rem;
            text-align: center;
            position: relative;
            border-bottom: 3px solid var(--primary-navy);
        }
        .header-actions {
            position: absolute;
            top: 1rem;
            right: 1.5rem;
            display: flex;
            gap: 0.75rem;
            z-index: 10;
        }
        .back-btn {
            padding: 0.3rem 0.6rem;
            border: 1px solid rgba(255,255,255,0.3);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.2s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }
        .back-btn:hover {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.5);
        }
        .language-switcher {
            display: flex;
            gap: 0.3rem;
        }
        .lang-btn {
            padding: 0.3rem 0.6rem;
            border: 1px solid rgba(255,255,255,0.3);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        .lang-btn:hover {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.5);
        }
        .lang-btn.active {
            background: white;
            color: var(--primary-navy);
            border-color: white;
        }
        .header h1 {
            font-size: 1.2rem;
            margin-bottom: 0.15rem;
            line-height: 1.3;
        }
        .header .subtitle {
            font-size: 0.9rem;
            margin-top: 0.25rem;
            opacity: 0.9;
        }
        .header .meta {
            margin-top: 0.5rem;
            font-size: 0.75rem;
            opacity: 0.8;
        }
        .content { padding: 1.5rem; }
        .section { margin-bottom: 1.5rem; page-break-inside: avoid; }
        .section-title {
            font-size: 1.4rem;
            color: #1a1a1a;
            margin-bottom: 0.4rem;
            padding-bottom: 0.25rem;
            border-bottom: 2px solid #1a1a1a;
        }
        .subsection-title {
            font-size: 1.1rem;
            color: #1a1a1a;
            margin-top: 1rem;
            margin-bottom: 0.5rem;
            font-weight: 600;
        }
        .executive-summary {
            background: #fafafa;
            border-left: 3px solid #e5e5e5;
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 4px;
        }
        .key-findings { list-style: none; }
        .key-findings li {
            padding: 0.4rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.95rem;
        }
        .key-findings li:before {
            content: "→";
            position: absolute;
            left: 0;
            color: #1a1a1a;
            font-weight: bold;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.7rem;
        }
        th, td { padding: 0.5rem; text-align: left; border-bottom: 1px solid #e5e5e5; }
        th { background: #fafafa; font-weight: 600; }
        tr:hover { background: #fafafa; }
        .chart-container {
            position: relative;
            height: 280px;
            margin: 1rem 0;
            padding: 0.75rem;
            border-radius: 4px;
            border: 1px solid #e5e5e5;
        }
        .sources {
            background: #fafafa;
            padding: 1rem;
            border-radius: 4px;
            margin-top: 1rem;
            font-size: 0.7rem;
        }
        .sources ul { list-style: none; }
        .sources li { padding: 0.25rem 0; }
        .sources a { color: #1a1a1a; text-decoration: none; }
        .trend-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin-bottom: 1rem; }
        .trend-card {
            background: white;
            border: 1px solid #e5e5e5;
            border-radius: 4px;
            padding: 1.5rem;
        }
        .trend-card h4 { font-size: 1rem; margin-bottom: 0.5rem; color: #1a1a1a; }
        .trend-card p { font-size: 0.9rem; line-height: 1.6; }
        .related-links {
            background: #f0f7ff;
            border-left: 3px solid #0052b8;
            padding: 0.75rem 1rem;
            margin: 1rem 0;
            border-radius: 4px;
            font-size: 0.9rem;
        }
        .related-links strong {
            color: #001e5c;
            font-size: 0.85rem;
            display: block;
            margin-bottom: 0.4rem;
        }
        .related-links a {
            color: #0052b8;
            text-decoration: none;
            font-weight: 500;
        }
        .related-links a:hover {
            text-decoration: underline;
        }
        .tech-badge {
            display: inline-block;
            background: #e8f4fd;
            color: #0052b8;
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-size: 0.75rem;
            margin-right: 0.3rem;
            margin-bottom: 0.3rem;
        }
        @media (max-width: 768px) {
            .trend-grid { grid-template-columns: 1fr; }
            .header-actions {
                position: static;
                display: flex;
                flex-direction: row;
                justify-content: center;
                align-items: center;
                gap: 0.5rem;
                margin-bottom: 1rem;
                flex-wrap: wrap;
            }
            .header {
                padding-top: 1rem;
                text-align: center;
            }
            .language-switcher {
                justify-content: center;
            }
            .back-btn {
                order: -1;
            }
        }
        @media print {
            body { padding: 0; font-size: 12px; }
            .container { box-shadow: none; }
            .header-actions { display: none; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="header-actions">
                <a href="../index.html" class="back-btn">← Home</a>
                <div class="language-switcher">
                    <button onclick="window.location.href='recsys-ai-algorithms-spotlight-20251215-ja.html'" class="lang-btn">日本語</button>
                    <button onclick="window.location.href='recsys-ai-algorithms-spotlight-20251215-ko.html'" class="lang-btn">한국어</button>
                    <button onclick="window.location.href='recsys-ai-algorithms-spotlight-20251215-en.html'" class="lang-btn active">English</button>
                </div>
            </div>
            <h1>AI Algorithms for Recommendation Systems<br>Top 5 Spotlight Technologies</h1>
            <div class="subtitle">From Transformers and Contrastive Learning to Knowledge Graphs and Multimodal Fusion</div>
            <div class="meta">Report Date: December 15, 2025 | Technology Deep Dive</div>
        </div>

        <div class="content">
            <!-- Technology Overview -->
            <section class="section">
                <h2 class="section-title">Technology Overview</h2>
                <p style="font-size: 0.9rem; color: #4a4a4a; margin-bottom: 1rem;">
                    Deep learning algorithms for recommendation systems are evolving rapidly, with a new generation of technologies emerging that go beyond traditional collaborative filtering. Various approaches including Transformers, contrastive learning, knowledge graphs, and generative models are being researched and implemented, contributing to improved accuracy and solving cold-start problems.
                </p>
                <div style="display: flex; flex-wrap: wrap; gap: 0.5rem; margin: 1rem 0;">
                    <span class="tech-badge">Transformer</span>
                    <span class="tech-badge">Self-Attention</span>
                    <span class="tech-badge">Contrastive Learning</span>
                    <span class="tech-badge">Knowledge Graph</span>
                    <span class="tech-badge">Multimodal Fusion</span>
                    <span class="tech-badge">VAE</span>
                    <span class="tech-badge">Diffusion Model</span>
                    <span class="tech-badge">GNN</span>
                </div>
            </section>

            <!-- SECTION 1: Top 5 Spotlight Technologies -->
            <section id="trends" class="section">
                <h2 class="section-title">Top 5 Spotlight Technologies</h2>

                <!-- Trend 1: Transformer-based Sequential Recommendation -->
                <h3 class="subsection-title">1. Transformer-Based Sequential Recommendation (SASRec·BERT4Rec·HydraRec)</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Sequential recommendation models using Self-Attention mechanisms have established themselves as state-of-the-art techniques for capturing dynamic preferences from user behavior history. SASRec and BERT4Rec serve as the two major baselines widely used in the field.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Representative Models</h4>
                        <p>• <strong>SASRec:</strong> Left-to-right unidirectional model, BCE loss with negative sampling<br>
                        • <strong>BERT4Rec:</strong> Bidirectional model, trained with Cloze task, full-item softmax<br>
                        • <strong>HydraRec (2025):</strong> Efficient attention mechanism, improved quadratic complexity for sequence length</p>
                    </div>
                    <div class="trend-card">
                        <h4>Latest Research (2025)</h4>
                        <p>• <strong>RSS (Recency Sampling):</strong> 60% NDCG improvement with RSS on SASRec, 16% over BERT4Rec, 93% training time reduction<br>
                        • <strong>eSASRec (RecSys 2025):</strong> Modular approach for improved scalability<br>
                        • <strong>TIGER:</strong> Outperforms SASRec, BERT4Rec, S3-Rec, P5 across all datasets</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://arxiv.org/abs/2501.01242" target="_blank">HydraRec Paper</a> |
                    <a href="https://arxiv.org/pdf/1904.06690" target="_blank">BERT4Rec Paper</a> |
                    <a href="https://github.com/NVIDIA-Merlin/Transformers4Rec" target="_blank">NVIDIA Transformers4Rec</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Implementation Notes:</strong> When using the same loss function, SASRec tends to outperform BERT4Rec in both quality and training speed. NVIDIA's Transformers4Rec library integrates with Hugging Face, making implementation straightforward.</p>

                <!-- Trend 2: Contrastive Learning -->
                <h3 class="subsection-title">2. Contrastive Learning-Based Self-Supervised Recommendation</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Contrastive learning frameworks inspired by SimCLR have been applied to recommendation systems, significantly improving robustness and accuracy through data augmentation and pair-wise learning.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Approaches</h4>
                        <p>• <strong>SGL (Self-supervised Graph Learning):</strong> Applies SimCLR paradigm to user-item graphs<br>
                        • <strong>SCL (Supervised Contrastive Learning):</strong> Learns similarity between users with similar interaction histories<br>
                        • <strong>FD-DCL (2025):</strong> Combines frequency domain separation with dual contrastive learning</p>
                    </div>
                    <div class="trend-card">
                        <h4>Technical Features</h4>
                        <p>• <strong>InfoNCE Loss:</strong> Maximizes positive pair similarity, minimizes negative pair similarity<br>
                        • <strong>Data Augmentation:</strong> Graph dropout, node masking, edge perturbation<br>
                        • <strong>Representation Learning:</strong> Aligns entity representations across different augmented views</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://github.com/google-research/simclr" target="_blank">SimCLR GitHub</a> |
                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122010668" target="_blank">SCL for Recommendation</a> |
                    <a href="https://arxiv.org/abs/2002.05709" target="_blank">SimCLR Original Paper</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Industry Applications:</strong> Deployed in production at Spotify (session-based recommendation) and Pinterest (content recommendation). Effectiveness validated on Gowalla, Yelp2018, and Amazon-Book datasets when combined with LightGCN.</p>

                <!-- Trend 3: Knowledge Graph Embedding -->
                <h3 class="subsection-title">3. Knowledge Graph Embedding (KGE) and Heterogeneous Information Networks</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Knowledge graphs contain rich multi-relational information and are effective for capturing item complementarity and users' latent interests. Modeling as Heterogeneous Information Networks (HIN) has become mainstream.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Techniques</h4>
                        <p>• <strong>TransE/TransR:</strong> Learn relations as translations in vector space (used in CFKG, CKE)<br>
                        • <strong>HKGAT (2025):</strong> Heterogeneous Knowledge Graph Attention Network for explainable recommendations<br>
                        • <strong>Meta-paths:</strong> Multi-dimensional characterization of user-item similarity</p>
                    </div>
                    <div class="trend-card">
                        <h4>Latest Trends (2025)</h4>
                        <p>• <strong>Hierarchical Graph Attention:</strong> Integration with multimodal knowledge graphs<br>
                        • <strong>GCL+KGE:</strong> Fusion of graph contrastive learning and knowledge graph embedding<br>
                        • <strong>KHGCN:</strong> Hierarchical Graph Capsule Network</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://link.springer.com/article/10.1007/s10489-025-06446-w" target="_blank">HKGAT (2025)</a> |
                    <a href="https://www.nature.com/articles/s41598-024-74516-z" target="_blank">Multi-level Contrastive KG</a> |
                    <a href="https://www.nature.com/articles/s41598-023-33984-5" target="_blank">Iterative HG Learning</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Challenges and Solutions:</strong> Setting uniform embedding dimensions for heterogeneous entities is challenging. Linear meta-paths struggle to express complex relational hierarchies, addressed through hierarchical attention mechanisms.</p>

                <!-- Trend 4: Multimodal Recommendation -->
                <h3 class="subsection-title">4. Multimodal Recommendation Systems (CLIP Fusion·MetaMMF)</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Recommendation systems integrating multiple modalities such as images, text, and audio are rapidly advancing. Large-scale pre-trained models like CLIP are used to generate semantically aligned embeddings.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Technical Architecture</h4>
                        <p>• <strong>Feature Extraction:</strong> CNN/ViT (images), BERT/SentenceTransformer (text), GNN (graphs)<br>
                        • <strong>CLIP Integration:</strong> Visual-language semantic alignment, though limited by inner product constraints<br>
                        • <strong>Fusion Strategies:</strong> Early fusion (low-level), late fusion (prediction-level), meta-learning</p>
                    </div>
                    <div class="trend-card">
                        <h4>Latest Research (2025)</h4>
                        <p>• <strong>MetaMMF:</strong> Meta-learning for dynamic per-micro-video parameter allocation<br>
                        • <strong>CLIP-Guided Feature Alignment:</strong> Self-Attention and Cross-Attention for cross-modal correlation enhancement<br>
                        • <strong>Differential Privacy:</strong> Privacy-preserving multimodal recommendation</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://dl.acm.org/doi/10.1145/3617827" target="_blank">MetaMMF Paper</a> |
                    <a href="https://arxiv.org/html/2411.17040v1" target="_blank">Multimodal Alignment Survey</a> |
                    <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0287927" target="_blank">Visual-Textual Fusion</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Emerging Trends:</strong> Multimodal, context-aware, and autonomous recommendations using LLMs, agentic planning, persistent memory, and adaptive behavior modules are emerging as important research directions.</p>

                <!-- Trend 5: Generative Recommendation Models -->
                <h3 class="subsection-title">5. Generative Recommendation Models (VAE·Diffusion·RAG)</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Generative recommendations using Variational Autoencoders (VAE) and diffusion models are robust against data sparsity and cold-start problems, enabling efficient Bayesian inference.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>VAE-Based Recommendation</h4>
                        <p>• <strong>Probabilistic Framework:</strong> Learning probability distributions in latent space, robust against data sparsity<br>
                        • <strong>Multi-Criteria Recommendation:</strong> Discovering how preferences in one criterion influence others<br>
                        • <strong>Challenges:</strong> Exposure bias, posterior collapse</p>
                    </div>
                    <div class="trend-card">
                        <h4>Diffusion Models & RAG</h4>
                        <p>• <strong>CODIGEM:</strong> First generative model applying diffusion process to recommendations<br>
                        • <strong>RAG Integration:</strong> Vector DB market $1.73B→$10.6B (2032), sub-100ms latency<br>
                        • <strong>Pinecone/Weaviate:</strong> Vector DBs for RAG recommendations</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://dl.acm.org/doi/10.1145/3663364" target="_blank">VAE in RecSys Survey</a> |
                    <a href="https://www.pinecone.io/learn/retrieval-augmented-generation/" target="_blank">Pinecone RAG Guide</a> |
                    <a href="https://www.mdpi.com/1999-4893/17/12/561" target="_blank">VAE Multi-Criteria RecSys</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Implementation Trends:</strong> PyTorch implementations of generative retrieval recommendation models using semantic IDs have been released. Latest techniques combining VAE with conditional U-Net in latent diffusion models are also emerging.</p>
            </section>

            <!-- SECTION 2: Technology Comparison and Selection Guide -->
            <section id="competitive" class="section">
                <h2 class="section-title">Technology Comparison and Selection Guide</h2>

                <h3 class="subsection-title">Algorithm Characteristics Comparison</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Technology</th>
                            <th>Strengths</th>
                            <th>Weaknesses</th>
                            <th>Use Cases</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Transformer-Based</strong><br>(SASRec/BERT4Rec)</td>
                            <td>Captures sequential dependencies, parallel computation</td>
                            <td>Computational cost increases with long sequences</td>
                            <td>Next-item prediction, session recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>Contrastive Learning</strong><br>(SGL/SCL)</td>
                            <td>Improved robustness, data augmentation effects</td>
                            <td>Negative sample selection is critical</td>
                            <td>Graph-based recommendation, sparse data</td>
                        </tr>
                        <tr>
                            <td><strong>Knowledge Graph</strong><br>(HKGAT/KGE)</td>
                            <td>Explainability, utilizes complementary information</td>
                            <td>KG construction cost, scalability</td>
                            <td>Explainable recommendation, cold-start</td>
                        </tr>
                        <tr>
                            <td><strong>Multimodal</strong><br>(CLIP/MetaMMF)</td>
                            <td>Rich feature utilization, semantic alignment</td>
                            <td>Computational cost, cross-modal gap</td>
                            <td>E-commerce, content recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>Generative</strong><br>(VAE/Diffusion)</td>
                            <td>Robust against data sparsity, probabilistic generation</td>
                            <td>Training stability, posterior collapse risk</td>
                            <td>Cold-start, diversity-focused</td>
                        </tr>
                    </tbody>
                </table>

                <h3 class="subsection-title">Technology Trend Comparison Chart</h3>
                <div class="chart-container">
                    <canvas id="techChart"></canvas>
                </div>

                <h3 class="subsection-title">2025 Technology Trend Highlights</h3>
                <ul style="font-size: 0.9rem; margin-left: 1.5rem; line-height: 1.8;">
                    <li><strong>Efficiency Focus:</strong> New architectures like HydraRec improving computational efficiency</li>
                    <li><strong>Hybrid Approaches:</strong> Combinations like Contrastive Learning+KG, Transformer+GNN becoming mainstream</li>
                    <li><strong>RAG Integration:</strong> Accelerating fusion of vector databases and recommendation systems</li>
                    <li><strong>Explainability:</strong> Growing interest in explainable recommendations in 2025 research like HKGAT</li>
                    <li><strong>Privacy Protection:</strong> Progress in differential privacy-applied multimodal recommendation research</li>
                </ul>
            </section>

            <!-- SECTION 3: Application Ideas -->
            <section id="application-ideas" class="section">
                <h2 class="section-title">Application Ideas</h2>
                <p style="margin-bottom: 1rem; color: #4a4a4a;">Practical approaches for applying each technology.</p>

                <div style="background: #fafafa; padding: 1.5rem; border-left: 3px solid #e5e5e5;">
                    <p style="margin-bottom: 1rem; line-height: 1.6;">1. <strong>Transformers4Rec Adoption</strong> - Rapid prototyping of SASRec/BERT4Rec with NVIDIA library, easy implementation through Hugging Face integration</p>
                    <p style="margin-bottom: 1rem; line-height: 1.6;">2. <strong>Contrastive Learning + LightGCN</strong> - Add SGL/SCL to existing GCN-based recommendations to validate robustness improvements</p>
                    <p style="line-height: 1.6;">3. <strong>RAG Recommendation Pilot</strong> - Build product vector DB with Pinecone/Weaviate, experiment with conversational recommendations combined with LLM</p>
                </div>
            </section>

            <!-- SECTION 4: Executive Summary -->
            <section id="executive-summary" class="section">
                <h2 class="section-title">Executive Summary</h2>

                <div class="executive-summary">
                    <h3 style="font-size: 1rem; margin-bottom: 0.4rem; color: #1a1a1a;">Key Findings</h3>
                    <ul class="key-findings">
                        <li><strong>Transformers Dominate:</strong> SASRec/BERT4Rec as dual baselines, RSS application achieves 60% NDCG improvement and 93% training time reduction simultaneously</li>
                        <li><strong>Contrastive Learning Proliferation:</strong> SimCLR paradigm penetrates recommendations as SGL/SCL, deployed at Spotify and Pinterest</li>
                        <li><strong>Knowledge Graph × Explainability:</strong> 2025 research like HKGAT advances explainable recommendation capabilities</li>
                        <li><strong>Multimodal Fusion:</strong> CLIP integration and meta-learning (MetaMMF) improve visual-textual-audio integrated accuracy</li>
                        <li><strong>Rise of RAG Recommendations:</strong> Vector DB market 10x growth ($1.7B→$10.6B), sub-100ms latency enables practical deployment</li>
                    </ul>

                    <h3 style="font-size: 1rem; margin-top: 1rem; margin-bottom: 0.5rem; color: #1a1a1a;">Technology Selection Guide</h3>
                    <p style="font-size: 0.9rem; line-height: 1.8;">
                        <strong>Rich Sequential Behavior Data → SASRec/BERT4Rec</strong><br>
                        Rapid implementation with Transformers4Rec, training efficiency with RSS<br><br>
                        <strong>Sparse Data · Robustness Priority → Contrastive Learning (SGL)</strong><br>
                        Performance validated with LightGCN combination<br><br>
                        <strong>Explainability · External Knowledge → Knowledge Graph (HKGAT)</strong><br>
                        For cold-start scenarios requiring recommendation explanations<br><br>
                        <strong>Multimedia Content → CLIP + Multimodal Fusion</strong><br>
                        Optimal for e-commerce, video, and music recommendations
                    </p>
                </div>

                <p style="margin-top: 1rem; font-size: 1rem; color: #4a4a4a;"><strong>Overall Assessment:</strong> Positive (Recommendation AI algorithms have entered maturity, evolving along three axes: efficiency, explainability, and multimodal support. Hybrid approaches have become mainstream, making technology selection based on use case crucial)</p>
            </section>

            <!-- SECTION 5: Key Terminology -->
            <section id="terminology" class="section">
                <h2 class="section-title" style="font-size: 1rem; margin-bottom: 0.4rem;">Key Terminology</h2>
                <div style="background: #fafafa; padding: 0.75rem; border-left: 3px solid #e5e5e5; font-size: 0.85rem;">
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Self-Attention</strong> - A mechanism where each element in an input sequence learns relevance to all other elements. Core technology of Transformers
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Contrastive Learning</strong> - Self-supervised learning that brings similar pairs closer and pushes dissimilar pairs apart. SimCLR is a representative example
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Knowledge Graph Embedding (KGE)</strong> - Technology that embeds entities and relations into vector space for reasoning
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>CLIP</strong> - OpenAI's visual-language pre-trained model. Learns semantic alignment between images and text
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>VAE (Variational Autoencoder)</strong> - Probabilistic latent variable model. Encodes inputs as probability distributions and generates through sampling
                    </div>
                    <div>
                        <strong>RAG (Retrieval-Augmented Generation)</strong> - Technique that retrieves relevant information from external knowledge bases and adds it to generative model inputs
                    </div>
                </div>
            </section>

            <!-- SECTION 6: Sources -->
            <section id="sources" class="section">
                <div class="sources">
                    <h3>Sources</h3>
                    <p><strong>Data Collection:</strong> December 15, 2025</p>
                    <ul>
                        <li>• <a href="https://arxiv.org/abs/2501.01242" target="_blank">HydraRec: An Efficient Attention Mechanism for Sequential Recommendation (2025)</a></li>
                        <li>• <a href="https://www.nature.com/articles/s41598-025-08931-1" target="_blank">Scientific Reports - Transformer-based CF Architecture (2025)</a></li>
                        <li>• <a href="https://github.com/NVIDIA-Merlin/Transformers4Rec" target="_blank">NVIDIA Transformers4Rec Library</a></li>
                        <li>• <a href="https://link.springer.com/article/10.1007/s10489-025-06446-w" target="_blank">HKGAT: Heterogeneous KG Attention Network (2025)</a></li>
                        <li>• <a href="https://dl.acm.org/doi/10.1145/3617827" target="_blank">MetaMMF: Meta-Learning Multimodal Fusion</a></li>
                        <li>• <a href="https://dl.acm.org/doi/10.1145/3663364" target="_blank">ACM Computing Surveys - VAE in Recommender Systems</a></li>
                        <li>• <a href="https://www.pinecone.io/learn/retrieval-augmented-generation/" target="_blank">Pinecone RAG Guide</a></li>
                        <li>• <a href="https://www.shaped.ai/blog/the-two-tower-model-for-recommendation-systems-a-deep-dive" target="_blank">Shaped - Two-Tower Model Deep Dive</a></li>
                        <li>• <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122010668" target="_blank">Supervised Contrastive Learning for Recommendation</a></li>
                        <li>• <a href="https://arxiv.org/html/2411.17040v1" target="_blank">Multimodal Alignment and Fusion Survey</a></li>
                    </ul>
                </div>
            </section>
        </div>
    </div>

    <script>
        const ctx = document.getElementById('techChart').getContext('2d');
        new Chart(ctx, {
            type: 'radar',
            data: {
                labels: ['Accuracy', 'Training Efficiency', 'Scalability', 'Explainability', 'Cold-Start Handling'],
                datasets: [
                    {
                        label: 'Transformer (SASRec)',
                        data: [90, 85, 80, 40, 50],
                        borderColor: 'rgb(59, 130, 246)',
                        backgroundColor: 'rgba(59, 130, 246, 0.15)',
                        pointBackgroundColor: 'rgb(59, 130, 246)'
                    },
                    {
                        label: 'Contrastive Learning (SGL)',
                        data: [85, 75, 85, 50, 70],
                        borderColor: 'rgb(34, 197, 94)',
                        backgroundColor: 'rgba(34, 197, 94, 0.15)',
                        pointBackgroundColor: 'rgb(34, 197, 94)'
                    },
                    {
                        label: 'Knowledge Graph (HKGAT)',
                        data: [80, 60, 65, 95, 85],
                        borderColor: 'rgb(249, 115, 22)',
                        backgroundColor: 'rgba(249, 115, 22, 0.15)',
                        pointBackgroundColor: 'rgb(249, 115, 22)'
                    },
                    {
                        label: 'Generative (VAE)',
                        data: [75, 70, 70, 60, 90],
                        borderColor: 'rgb(168, 85, 247)',
                        backgroundColor: 'rgba(168, 85, 247, 0.15)',
                        pointBackgroundColor: 'rgb(168, 85, 247)'
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: {
                        position: 'bottom',
                        labels: {
                            font: { size: 11 },
                            padding: 15
                        }
                    }
                },
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 100,
                        ticks: {
                            stepSize: 20,
                            font: { size: 10 }
                        },
                        pointLabels: {
                            font: { size: 11 }
                        }
                    }
                }
            }
        });
    </script>
</body>
</html>
