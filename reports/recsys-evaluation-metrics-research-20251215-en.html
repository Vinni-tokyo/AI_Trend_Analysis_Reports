<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Recommendation System Evaluation Metrics and Quality Measurement: Academic Research and Latest Technologies</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --primary-navy: #001e5c;
            --secondary-navy: #003d8f;
            --accent-navy: #0052b8;
            --primary-color: #1a1a1a;
            --secondary-color: #4a4a4a;
            --tertiary-color: #808080;
            --bg-white: #ffffff;
            --bg-subtle: #fafafa;
            --border-color: #e5e5e5;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.7;
            color: #1a1a1a;
            background: #fafafa;
            padding: 0;
            font-size: 16px;
            font-weight: 400;
        }
        .container {
            max-width: 1000px;
            margin: 2rem auto;
            background: white;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }
        .header {
            background: linear-gradient(135deg, var(--primary-navy) 0%, var(--secondary-navy) 100%);
            color: white;
            padding: 2rem 2.5rem 1.5rem;
            text-align: center;
            position: relative;
            border-bottom: 3px solid var(--primary-navy);
        }
        .header-actions {
            position: absolute;
            top: 1rem;
            right: 1.5rem;
            display: flex;
            gap: 0.75rem;
            z-index: 10;
        }
        .back-btn {
            padding: 0.3rem 0.6rem;
            border: 1px solid rgba(255,255,255,0.3);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.2s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }
        .back-btn:hover {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.5);
        }
        .language-switcher {
            display: flex;
            gap: 0.3rem;
        }
        .lang-btn {
            padding: 0.3rem 0.6rem;
            border: 1px solid rgba(255,255,255,0.3);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        .lang-btn:hover {
            background: rgba(255,255,255,0.2);
            border-color: rgba(255,255,255,0.5);
        }
        .lang-btn.active {
            background: white;
            color: var(--primary-navy);
            border-color: white;
        }
        .header h1 {
            font-size: 1.2rem;
            margin-bottom: 0.15rem;
            line-height: 1.3;
        }
        .header .subtitle {
            font-size: 0.9rem;
            margin-top: 0.25rem;
            opacity: 0.9;
        }
        .header .meta {
            margin-top: 0.5rem;
            font-size: 0.75rem;
            opacity: 0.8;
        }
        .content { padding: 1.5rem; }
        .section { margin-bottom: 1.5rem; page-break-inside: avoid; }
        .section-title {
            font-size: 1.4rem;
            color: #1a1a1a;
            margin-bottom: 0.4rem;
            padding-bottom: 0.25rem;
            border-bottom: 2px solid #1a1a1a;
        }
        .subsection-title {
            font-size: 1.1rem;
            color: #1a1a1a;
            margin-top: 1rem;
            margin-bottom: 0.5rem;
            font-weight: 600;
        }
        .executive-summary {
            background: #fafafa;
            border-left: 3px solid #e5e5e5;
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 4px;
        }
        .key-findings { list-style: none; }
        .key-findings li {
            padding: 0.4rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.95rem;
        }
        .key-findings li:before {
            content: "→";
            position: absolute;
            left: 0;
            color: #1a1a1a;
            font-weight: bold;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.7rem;
        }
        th, td { padding: 0.5rem; text-align: left; border-bottom: 1px solid #e5e5e5; }
        th { background: #fafafa; font-weight: 600; }
        tr:hover { background: #fafafa; }
        .chart-container {
            position: relative;
            height: 280px;
            margin: 1rem 0;
            padding: 0.75rem;
            border-radius: 4px;
            border: 1px solid #e5e5e5;
        }
        .sources {
            background: #fafafa;
            padding: 1rem;
            border-radius: 4px;
            margin-top: 1rem;
            font-size: 0.7rem;
        }
        .sources ul { list-style: none; }
        .sources li { padding: 0.25rem 0; }
        .sources a { color: #1a1a1a; text-decoration: none; }
        .trend-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin-bottom: 1rem; }
        .trend-card {
            background: white;
            border: 1px solid #e5e5e5;
            border-radius: 4px;
            padding: 1.5rem;
        }
        .trend-card h4 { font-size: 1rem; margin-bottom: 0.5rem; color: #1a1a1a; }
        .trend-card p { font-size: 0.9rem; line-height: 1.6; }
        .related-links {
            background: #f0f7ff;
            border-left: 3px solid #0052b8;
            padding: 0.75rem 1rem;
            margin: 1rem 0;
            border-radius: 4px;
            font-size: 0.9rem;
        }
        .related-links strong {
            color: #001e5c;
            font-size: 0.85rem;
            display: block;
            margin-bottom: 0.4rem;
        }
        .related-links a {
            color: #0052b8;
            text-decoration: none;
            font-weight: 500;
        }
        .related-links a:hover {
            text-decoration: underline;
        }
        .tech-badge {
            display: inline-block;
            background: #e8f4fd;
            color: #0052b8;
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-size: 0.75rem;
            margin-right: 0.3rem;
            margin-bottom: 0.3rem;
        }
        @media (max-width: 768px) {
            .trend-grid { grid-template-columns: 1fr; }
            .header-actions {
                position: static;
                display: flex;
                flex-direction: row;
                justify-content: center;
                align-items: center;
                gap: 0.5rem;
                margin-bottom: 1rem;
                flex-wrap: wrap;
            }
            .header {
                padding-top: 1rem;
                text-align: center;
            }
            .language-switcher {
                justify-content: center;
            }
            .back-btn {
                order: -1;
            }
        }
        @media print {
            body { padding: 0; font-size: 12px; }
            .container { box-shadow: none; }
            .header-actions { display: none; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="header-actions">
                <a href="../index.html" class="back-btn">← Home</a>
                <div class="language-switcher">
                    <button onclick="window.location.href='recsys-evaluation-metrics-research-20251215-ja.html'" class="lang-btn">日本語</button>
                    <button onclick="window.location.href='recsys-evaluation-metrics-research-20251215-ko.html'" class="lang-btn">한국어</button>
                    <button onclick="window.location.href='recsys-evaluation-metrics-research-20251215-en.html'" class="lang-btn active">English</button>
                </div>
            </div>
            <h1>Recommendation System Evaluation Metrics<br>and Quality Measurement</h1>
            <div class="subtitle">From NDCG, Diversity, Fairness to LLM-as-Judge</div>
            <div class="meta">Report Date: December 15, 2025 | Academic Research & Technology Analysis</div>
        </div>

        <div class="content">
            <!-- Technology Overview -->
            <section class="section">
                <h2 class="section-title">Technology Overview</h2>
                <p style="font-size: 0.9rem; color: #4a4a4a; margin-bottom: 1rem;">
                    Recommendation system evaluation has evolved from simple accuracy metrics to multifaceted approaches. Beyond traditional NDCG, Precision, and Recall, "Beyond-Accuracy" metrics such as diversity, novelty, and fairness have gained importance. Furthermore, counterfactual evaluation to bridge the gap between offline and online evaluation, and new paradigms using LLMs as evaluators have emerged.
                </p>
                <div style="display: flex; flex-wrap: wrap; gap: 0.5rem; margin: 1rem 0;">
                    <span class="tech-badge">NDCG</span>
                    <span class="tech-badge">Precision@K</span>
                    <span class="tech-badge">MRR</span>
                    <span class="tech-badge">Diversity</span>
                    <span class="tech-badge">Serendipity</span>
                    <span class="tech-badge">Fairness</span>
                    <span class="tech-badge">Counterfactual</span>
                    <span class="tech-badge">LLM-as-Judge</span>
                </div>
            </section>

            <!-- SECTION 1: Top 5 Spotlight Technologies -->
            <section id="trends" class="section">
                <h2 class="section-title">Top 5 Spotlight Technologies</h2>

                <!-- Trend 1: Ranking Evaluation Metrics -->
                <h3 class="subsection-title">1. Evolution of Ranking Evaluation Metrics (NDCG·MRR·MAP)</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> NDCG (Normalized Discounted Cumulative Gain) remains a key evaluation metric for recommendation and search systems in 2024-2025. However, research on comparison distortions caused by normalization is ongoing, requiring careful usage.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Metric Characteristics</h4>
                        <p>• <strong>NDCG@K:</strong> Considers graded relevance, higher scores for relevant items at top positions<br>
                        • <strong>MRR:</strong> Average of reciprocal ranks of first correct item, highly interpretable<br>
                        • <strong>MAP@K:</strong> Most popular for recommender systems, NDCG dominates in search</p>
                    </div>
                    <div class="trend-card">
                        <h4>2025 Research Trends</h4>
                        <p>• <strong>Jeunen et al. (2024):</strong> NDCG normalization can reverse correlation with actual online rewards<br>
                        • <strong>RecBole Validation:</strong> Same algorithm yields different results across frameworks<br>
                        • <strong>Composite Metrics:</strong> Multi-metric evaluation recommended over single metrics</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://arxiv.org/html/2312.16015v2" target="_blank">Comprehensive Survey of Evaluation Techniques</a> |
                    <a href="https://www.shaped.ai/blog/evaluating-recommendation-systems-map-mmr-ndcg" target="_blank">Shaped: Evaluation Metrics Guide</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Usage Guide:</strong> Use NDCG for graded relevance, MRR for single-answer scenarios, MAP@K for general recommendation systems.</p>

                <!-- Trend 2: Beyond-Accuracy Metrics -->
                <h3 class="subsection-title">2. Beyond-Accuracy Metrics (Diversity·Novelty·Fairness)</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Beyond accuracy, metrics such as diversity, serendipity, and fairness have been shown to strongly influence user engagement and satisfaction.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Concepts</h4>
                        <p>• <strong>Diversity:</strong> Dissimilarity among items in recommendation list, measured by Gini index or entropy<br>
                        • <strong>Novelty:</strong> Probability of users discovering unknown items<br>
                        • <strong>Serendipity:</strong> Discovery of unexpected yet useful items</p>
                    </div>
                    <div class="trend-card">
                        <h4>Fairness Perspectives</h4>
                        <p>• <strong>User Fairness:</strong> Eliminating bias toward specific user groups<br>
                        • <strong>Item Fairness:</strong> Equal exposure opportunities countering popularity bias<br>
                        • <strong>GNN Research:</strong> Personalized diversity emerging as new research direction</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://www.frontiersin.org/journals/big-data/articles/10.3389/fdata.2023.1251072/full" target="_blank">Beyond-Accuracy Review (Frontiers)</a> |
                    <a href="https://arxiv.org/abs/2310.02294" target="_blank">GNN-based RecSys Beyond-Accuracy Survey</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Outlook:</strong> 2025 research highlights generative models potentially amplifying training data biases and personalized diversity (adjusting diversity levels per user) as emerging challenges.</p>

                <!-- Trend 3: Offline·Online Evaluation and Counterfactual -->
                <h3 class="subsection-title">3. Counterfactual Evaluation and A/B Testing Efficiency</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Counterfactual evaluation methods are gaining attention for bridging the gap between offline and online A/B testing. Airbnb achieved 100x speedup compared to A/B testing in 2025 by combining interleaving with counterfactual evaluation.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Counterfactual Evaluation Core</h4>
                        <p>• <strong>IPS (Inverse Propensity Score):</strong> Corrects selection bias in logged data<br>
                        • <strong>SNIPS:</strong> Self-normalized IPS, most stable performance<br>
                        • <strong>Direct Method:</strong> Inferior to IPS as data increases</p>
                    </div>
                    <div class="trend-card">
                        <h4>Airbnb Results (KDD 2025)</h4>
                        <p>• <strong>Interleaving:</strong> 50x speedup compared to A/B testing<br>
                        • <strong>Counterfactual Evaluation:</strong> Additional sensitivity improvement, 100x speedup<br>
                        • <strong>Production Use:</strong> Applied for A/B test candidate selection</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://arxiv.org/html/2508.00751v1" target="_blank">Airbnb Counterfactual Evaluation (KDD 2025)</a> |
                    <a href="https://eugeneyan.com/writing/counterfactual-evaluation/" target="_blank">Eugene Yan: Counterfactual Evaluation Guide</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Academic Trends:</strong> 2025 ACM publications include Off-Policy Evaluation for Matching Markets, Counterfactual Inference under Thompson Sampling, and Bayesian Perspectives on Offline Evaluation.</p>

                <!-- Trend 4: LLM-as-Judge -->
                <h3 class="subsection-title">4. Rise of LLM-as-Judge Evaluators</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> The LLM-as-Judge paradigm, using large language models like GPT-4 as evaluators, is rapidly spreading. It achieves approximately 80% agreement with human evaluators and demonstrates significant advantages in scalability and efficiency.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Frameworks</h4>
                        <p>• <strong>G-Eval:</strong> For NLG evaluation, high agreement with humans using GPT-4<br>
                        • <strong>RecSys Application:</strong> K-means+CBF+GPT-4 improves recommendation accuracy<br>
                        • <strong>Evaluation Criteria:</strong> Convincingness, clarity, accuracy, decision impact</p>
                    </div>
                    <div class="trend-card">
                        <h4>Challenges and Considerations</h4>
                        <p>• <strong>Biases:</strong> Verbosity bias, position bias exist<br>
                        • <strong>Self-Style Preference:</strong> GPT-4 tends to favor its own writing style<br>
                        • <strong>RecSys 2023:</strong> Research on ChatGPT fairness evaluation</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://www.evidentlyai.com/llm-guide/llm-as-a-judge" target="_blank">Evidently AI: LLM-as-Judge Guide</a> |
                    <a href="https://www.mdpi.com/2674-113X/3/1/4" target="_blank">GPT-4 for Recommendation Evaluation (MDPI)</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Practical Value:</strong> Significantly improved cost efficiency compared to human evaluation. Widely applied for agents, RAG, and chatbot evaluation. Outputs 0-1 scores, optimal for unit testing.</p>

                <!-- Trend 5: Explainability Evaluation -->
                <h3 class="subsection-title">5. Explainability Evaluation (XAI Metrics)</h3>
                <p style="font-size: 0.9rem;"><strong>Overview:</strong> Metrics for quantitatively evaluating recommendation system explainability are being researched. Multifaceted evaluation including fidelity, simplicity, and consistency is required.</p>

                <div class="trend-grid">
                    <div class="trend-card">
                        <h4>Key Evaluation Metrics</h4>
                        <p>• <strong>Fidelity:</strong> Whether explanations accurately describe model behavior<br>
                        • <strong>Simplicity:</strong> Selecting only necessary and sufficient features<br>
                        • <strong>Robustness:</strong> Stability against minor perturbations</p>
                    </div>
                    <div class="trend-card">
                        <h4>RecSys-Specific Metrics</h4>
                        <p>• <strong>Max Explainability Score:</strong> Integrates rule count, path probability, entropy, reward<br>
                        • <strong>Co-12 Properties:</strong> Completeness, correctness, compactness<br>
                        • <strong>LLM Evaluation:</strong> Convincingness, clarity, decision impact</p>
                    </div>
                </div>

                <div class="related-links">
                    <strong>Related Links:</strong>
                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0045790624001186" target="_blank">Max Explainability Score (ScienceDirect)</a> |
                    <a href="https://www.mdpi.com/2076-3417/14/23/11288" target="_blank">Empirical XAI Evaluation Overview</a>
                </div>

                <p style="font-size: 0.9rem;"><strong>Challenges:</strong> Subjectivity, context dependency, and user dependency make developing universal computational metrics difficult. Combining with qualitative user feedback is recommended.</p>
            </section>

            <!-- SECTION 2: Benchmarks and Framework Comparison -->
            <section id="competitive" class="section">
                <h2 class="section-title">Benchmarks and Framework Comparison</h2>

                <h3 class="subsection-title">Major Benchmark Datasets</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Dataset</th>
                            <th>Scale</th>
                            <th>Features</th>
                            <th>Use Case</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>MovieLens 32M</strong></td>
                            <td>32M ratings, 200K users</td>
                            <td>Released May 2024, includes tag genome</td>
                            <td>Collaborative filtering, large-scale research</td>
                        </tr>
                        <tr>
                            <td><strong>Amazon Reviews</strong></td>
                            <td>Hundreds of millions implicit feedback</td>
                            <td>Product interactions, diverse categories</td>
                            <td>E-commerce recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>MIND</strong></td>
                            <td>15M impressions</td>
                            <td>Microsoft News, 160K articles</td>
                            <td>News recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>Yelp</strong></td>
                            <td>Reviews + implicit feedback</td>
                            <td>Includes business metadata</td>
                            <td>POI recommendation, review analysis</td>
                        </tr>
                    </tbody>
                </table>

                <h3 class="subsection-title">Evaluation Framework Comparison</h3>
                <div class="chart-container">
                    <canvas id="frameworkChart"></canvas>
                </div>

                <h3 class="subsection-title">Metric Selection Guide</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Metric Category</th>
                            <th>Representative Metrics</th>
                            <th>Optimal Use Cases</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Accuracy Metrics</strong></td>
                            <td>NDCG, MAP, MRR, Precision@K</td>
                            <td>Relevance-focused, basic search/recommendation evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>Beyond-Accuracy</strong></td>
                            <td>Diversity, Novelty, Serendipity</td>
                            <td>User experience, long-term engagement</td>
                        </tr>
                        <tr>
                            <td><strong>Fairness</strong></td>
                            <td>Gini Index, Entropy, Coverage</td>
                            <td>Item exposure equality, bias detection</td>
                        </tr>
                        <tr>
                            <td><strong>Offline Evaluation</strong></td>
                            <td>IPS, SNIPS, Counterfactual</td>
                            <td>Candidate selection before A/B testing</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- SECTION 3: Application Ideas -->
            <section id="application-ideas" class="section">
                <h2 class="section-title">Application Ideas</h2>
                <p style="margin-bottom: 1rem; color: #4a4a4a;">Key approaches observed in research and practice.</p>

                <div style="background: #fafafa; padding: 1.5rem; border-left: 3px solid #e5e5e5;">
                    <p style="margin-bottom: 1rem; line-height: 1.6;">1. <strong>Multi-Metric Evaluation with RecBole</strong> - Simultaneously measure NDCG, Diversity, Fairness using unified framework and visualize trade-offs</p>
                    <p style="margin-bottom: 1rem; line-height: 1.6;">2. <strong>LLM-as-Judge Implementation</strong> - Automatically evaluate recommendation explanation quality with GPT-4, reducing human evaluation costs and improving consistency</p>
                    <p style="line-height: 1.6;">3. <strong>Counterfactual Evaluation Pilot</strong> - Conduct IPS-based evaluation before A/B testing to accelerate candidate system filtering</p>
                </div>
            </section>

            <!-- SECTION 4: Executive Summary -->
            <section id="executive-summary" class="section">
                <h2 class="section-title">Executive Summary</h2>

                <div class="executive-summary">
                    <h3 style="font-size: 1rem; margin-bottom: 0.4rem; color: #1a1a1a;">Key Findings</h3>
                    <ul class="key-findings">
                        <li><strong>NDCG Remains Dominant but Requires Caution:</strong> Research on normalization-induced comparison distortions ongoing, composite metrics recommended</li>
                        <li><strong>Importance of Beyond-Accuracy Metrics:</strong> Diversity and fairness strongly impact user satisfaction and engagement</li>
                        <li><strong>Counterfactual Evaluation Practicalization:</strong> Airbnb achieved 100x speedup, contributing to A/B testing efficiency</li>
                        <li><strong>Rise of LLM-as-Judge:</strong> GPT-4 achieves 80% agreement with human evaluators, excellent cost efficiency and scalability</li>
                        <li><strong>Explainability Evaluation Challenges:</strong> Universal metric development difficult due to subjectivity and context dependency</li>
                    </ul>

                    <h3 style="font-size: 1rem; margin-top: 1rem; margin-bottom: 0.5rem; color: #1a1a1a;">Metric Selection Guide</h3>
                    <p style="font-size: 0.9rem; line-height: 1.8;">
                        <strong>Relevance-Focused Basic Evaluation → NDCG + MAP@K</strong><br>
                        Standard for search/recommendation, NDCG for graded relevance<br><br>
                        <strong>User Experience · Long-Term Engagement → Diversity + Novelty</strong><br>
                        Prevent over-specialization, promote discovery experiences<br><br>
                        <strong>A/B Testing Efficiency → IPS/SNIPS + Interleaving</strong><br>
                        Filter candidates with offline evaluation, streamline online testing<br><br>
                        <strong>Explanation Quality Evaluation → LLM-as-Judge + User Studies</strong><br>
                        Combine quantitative evaluation with qualitative feedback
                    </p>
                </div>

                <p style="margin-top: 1rem; font-size: 1rem; color: #4a4a4a;"><strong>Overall Assessment:</strong> Positive (Recommendation system evaluation is maturing from accuracy-centric to multifaceted evaluation, with new technologies like LLM utilization and counterfactual evaluation being put into practice)</p>
            </section>

            <!-- SECTION 5: Key Terminology -->
            <section id="terminology" class="section">
                <h2 class="section-title" style="font-size: 1rem; margin-bottom: 0.4rem;">Key Terminology</h2>
                <div style="background: #fafafa; padding: 0.75rem; border-left: 3px solid #e5e5e5; font-size: 0.85rem;">
                    <div style="margin-bottom: 0.5rem;">
                        <strong>NDCG (Normalized Discounted Cumulative Gain)</strong> - Metric measuring ranking quality. Higher scores for placing highly relevant items at top positions
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>MRR (Mean Reciprocal Rank)</strong> - Average of reciprocal ranks of first correct item. Easy to interpret but unsuitable for multiple correct answers
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>IPS (Inverse Propensity Score)</strong> - Counterfactual evaluation technique correcting selection bias in logged data
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>LLM-as-Judge</strong> - Paradigm using large language models like GPT-4 as evaluators
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>Serendipity</strong> - Discovery of unexpected yet useful items. Fortunate accidental discovery
                    </div>
                    <div>
                        <strong>RecBole</strong> - Unified PyTorch-based recommendation system library. Provides various recommendation paradigms and benchmarks
                    </div>
                </div>
            </section>

            <!-- SECTION 6: Sources -->
            <section id="sources" class="section">
                <div class="sources">
                    <h3>Sources</h3>
                    <p><strong>Data Collection:</strong> December 15, 2025</p>
                    <ul>
                        <li>• <a href="https://arxiv.org/html/2312.16015v2" target="_blank">A Comprehensive Survey of Evaluation Techniques for Recommendation Systems (arXiv 2024)</a></li>
                        <li>• <a href="https://www.frontiersin.org/journals/big-data/articles/10.3389/fdata.2023.1251072/full" target="_blank">Beyond-Accuracy: Diversity, Serendipity, Fairness in GNN RecSys (Frontiers 2023)</a></li>
                        <li>• <a href="https://arxiv.org/html/2508.00751v1" target="_blank">Airbnb: Interleaving and Counterfactual Evaluation (KDD 2025)</a></li>
                        <li>• <a href="https://www.mdpi.com/2674-113X/3/1/4" target="_blank">GPT-4 LLM for Enhanced Recommender Systems (MDPI 2024)</a></li>
                        <li>• <a href="https://dl.acm.org/doi/10.1145/3556536" target="_blank">Evaluating Recommender Systems: Survey and Framework (ACM Computing Surveys 2022)</a></li>
                        <li>• <a href="https://recbole.io/dataset_list.html" target="_blank">RecBole Dataset List</a></li>
                        <li>• <a href="https://grouplens.org/datasets/movielens/" target="_blank">MovieLens Datasets (GroupLens)</a></li>
                        <li>• <a href="https://www.evidentlyai.com/llm-guide/llm-as-a-judge" target="_blank">Evidently AI: LLM-as-a-Judge Complete Guide</a></li>
                        <li>• <a href="https://www.sciencedirect.com/science/article/abs/pii/S0045790624001186" target="_blank">Max Explainability Score for KG Recommendations (ScienceDirect 2024)</a></li>
                        <li>• <a href="https://link.springer.com/article/10.1007/s11042-024-20262-3" target="_blank">Deep Learning for Cold Start and Long Tail (Springer 2025)</a></li>
                    </ul>
                </div>
            </section>
        </div>
    </div>

    <script>
        const ctx = document.getElementById('frameworkChart').getContext('2d');
        new Chart(ctx, {
            type: 'radar',
            data: {
                labels: ['Accuracy Metrics', 'Beyond-Accuracy', 'Offline Evaluation', 'Explainability', 'Scalability'],
                datasets: [
                    {
                        label: 'RecBole',
                        data: [95, 80, 85, 60, 90],
                        borderColor: 'rgb(59, 130, 246)',
                        backgroundColor: 'rgba(59, 130, 246, 0.15)',
                        pointBackgroundColor: 'rgb(59, 130, 246)'
                    },
                    {
                        label: 'Elliot',
                        data: [90, 85, 75, 70, 75],
                        borderColor: 'rgb(34, 197, 94)',
                        backgroundColor: 'rgba(34, 197, 94, 0.15)',
                        pointBackgroundColor: 'rgb(34, 197, 94)'
                    },
                    {
                        label: 'Cornac',
                        data: [85, 75, 70, 65, 80],
                        borderColor: 'rgb(249, 115, 22)',
                        backgroundColor: 'rgba(249, 115, 22, 0.15)',
                        pointBackgroundColor: 'rgb(249, 115, 22)'
                    },
                    {
                        label: 'LensKit',
                        data: [80, 70, 80, 55, 85],
                        borderColor: 'rgb(168, 85, 247)',
                        backgroundColor: 'rgba(168, 85, 247, 0.15)',
                        pointBackgroundColor: 'rgb(168, 85, 247)'
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: {
                        position: 'bottom',
                        labels: {
                            font: { size: 11 },
                            padding: 15
                        }
                    }
                },
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 100,
                        ticks: {
                            stepSize: 20,
                            font: { size: 10 }
                        },
                        pointLabels: {
                            font: { size: 11 }
                        }
                    }
                }
            }
        });
    </script>
</body>
</html>
